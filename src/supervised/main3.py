
from graph_utils import read_instagram_genrace
from dataset_utils import make_5_recofiles, make_5_trainfiles # make_5_testfiles
from bias_metrics import get_biasDist_genrace, write_topRecos, count_groups, sort_Reco, getROCs, grow#, get_bias_genrace,get_degree_dist, get_accuracies, get_Equality_opportunity, get_Disparate_impact,
#from plot_utils import plot_bias

DATAPATH= "../../data/london/"

# reading pickles
gender, race = read_instagram_genrace(DATAPATH + 'london.genrace')


### The code below is for fairness by the attribute gender, coded for race is similar and in ,main_race.py

#calculate features for the friend and stranger pairs of the training set from the embeddings generated by main1.py
make_5_trainfiles(gender, DATAPATH)


#calculate features for "regular" candidate pairs as generated by main2.py file
make_5_recofiles(gender, DATAPATH,embfile='known_80_80_20_128.emb', pickfile_frn="known_80_top100.pick", pickfile_str="known_80_rand.pick", testfile_suffix= "hada_100_test_2.csv")
#calculate features for "FAIR" candidate pairs as generated by main2.py file
make_5_recofiles(gender, DATAPATH,embfile='known_80_gendeq_80_20_128.emb', pickfile_frn="known_80_gendeq_top100.pick" , pickfile_str="known_80_rand.pick", testfile_suffix= "hada_100_test_geneq_2.csv")


#train classifier and sort candidates by positive class probability
sort_Reco(DATAPATH, testfile= "hada_100_test_2.csv", reco_file= "recommendations.csv")
sort_Reco(DATAPATH, testfile= "hada_100_test_geneq_2.csv", reco_file= "recommendations_geneq.csv")


#Rank candidate pairs and recommend top pairs depending on desired growth of network
write_topRecos(DATAPATH, growth=0.2, testfile="hada_100_test_2.csv", reco_file= "recommendations.csv", toprecofile="topRecos.edgelist")
write_topRecos(DATAPATH, growth=0.2, testfile="hada_100_test_geneq_2.csv", reco_file= "recommendations_geneq.csv", toprecofile="topRecos_geneq.edgelist")



